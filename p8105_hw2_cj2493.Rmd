---
title: "p8105_hw2_cj2493"
author: "Courtney Johnson"
date: "September 28, 2018"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
```

## Problem 1

Read and clean the data; retain line, station name, station latitude/longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character to logical.

```{r, clean}
subway_data = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(c(line:entry), vending, ada) %>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE)) 
```

Describe the dataset:

This dataset contains information on the NYC subway. Each observation has a station name, the line it's on, its latitude and longitude, the route(s) it serves, if you can enter the station, if there is vending, what type of entrance the station has, and if it is ADA compliant. There is a maximum of 11 routes served for each station. 

To clean the dataset, I started by cleaning the names to a lower case and snakecase format. Then I selected all the necessary variables. Because most of the variables we want to keep are all next to each other, we can choose to select most of the variables with a vector. Next, I changed the entry variable to a logical variable with mutate() and recode().  

The dataset has `r nrow(subway_data)` rows and `r ncol(subway_data)` columns. These data are not tidy, because we could gather the routes served and get rid of duplicates.


```{r, distinct_station}
subway_distinct_stations = distinct(subway_data, station_name, line, .keep_all = TRUE)
subway_no_vending = filter(subway_distinct_stations, vending == "NO")
```

There are `r nrow(subway_distinct_stations)` distinct stations. `r sum(subway_distinct_stations$ada)` stations are ADA compliant. The proportion of station entrances/exits without vending that allow entrance is `r sum(subway_no_vending$entry)/nrow(subway_no_vending)`.


Here we are asked to make route number and route name distinct variables, so we can do this with the gather step.

```{r, distinct_route}
subway_distinct_route = gather(subway_data, key = route_number, value = route, route1:route11) %>%
  filter(route == "A") %>%
  distinct(station_name, line, .keep_all = TRUE) 
```


`r nrow(subway_distinct_route)` distinct stations serve the A train.
Of the stations that serve the A train, `r sum(subway_distinct_route$ada)` are ADA compliant.


## Problem 2

Read and clean the Mr. Trash Wheel dataset:

```{r, mr_trash_wheel}
mr_trash_wheel_data = read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = "Mr. Trash Wheel", range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster), !is.na(date)) %>%
  mutate(sports_balls = as.integer(sports_balls))
```

Read and clean precipitation data for 2016 and 2017: 

```{r, precipitation}
precip_17_data = read_xlsx("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet  = "2017 Precipitation", range = "A2:B14", col_names = TRUE) %>%
  janitor::clean_names() %>%
  mutate(year = 2017) %>%
  filter(!is.na(total))

precip_16_data = read_xlsx("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet  = "2016 Precipitation", range = "A2:B14", col_names = TRUE) %>%
  janitor::clean_names() %>%
  mutate(year = 2016) %>%
  filter(!is.na(total))

precip_data = bind_rows(precip_16_data, precip_17_data) %>%
  mutate(month = month.name[month]) %>%
  select(month, year, total)
```

Describe the data:

The Mr. Trash Wheel dataset has `r nrow(mr_trash_wheel_data)` observations of `r ncol(mr_trash_wheel_data)` variables. The joined dataset of precipitation in 2016 and 2017 has `r nrow(precip_data)` observations of `r ncol(precip_data)` variables.

The Mr. Trash Wheel dataset includes information on specific dumpsters on specific dates. Some of the variables measured per dumpster include weight in tons, volume in cubic yards, and the amount of specific items in the dumpster, like plastic bottles. The only variables of in the preciptation dataset are month, year, and total precipitation in inches. 

The data for precipitation in 2016 has information for `r nrow(precip_16_data)` months, and the data for precipitation in 2017 has information for `r nrow(precip_17_data)` months. For available data, the total precipitation in 2017 was `r sum(precip_17_data$total)`
 inches. The median number of sports balls in a dumpster in 2016 is `r median(filter(mr_trash_wheel_data, year == 2016)$sports_balls)`.
 
## Problem 3

Load BRFSS data from the p8105.datasets package: 

```{r, p8105_data}
library(devtools)
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data(brfss_smart2010)
```

Clean the brfss data by formatting data with appropriate variable names, focusing on data about the "Overall Health" topic, excluding variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation. Structure data so that values for Response become variables that indicate the proportion of subjects with each response. Create a new variable showing the proportion of responses that were Excellent or Very Good. 

```{r, tidy_brfss}
brfss_smart2010 = janitor::clean_names(brfss_smart2010) %>%
  filter(topic == "Overall Health") %>%
  select(-class, -topic, -question, -sample_size, -c(confidence_limit_low:geo_location)) %>%
  spread(key = response, value = data_value) %>%
  janitor::clean_names() %>%
  mutate(excellent_OR_very_good = excellent + very_good)
```

Create manipulated versions of the data in order to better answer questions about the data. 

```{r, state_freq}
library(openintro)
location_freq = count(brfss_smart2010, locationdesc)
state_freq = count(brfss_smart2010, locationabbr)
state_most = abbr2state(as.character(state_freq[which.max(state_freq$n),1]))
```


There are `r nrow(location_freq)` locations included in the dataset. There are `r nrow(state_freq)` states included, so all 50 states and the District of Columbia are represented. The state that is represented the most is `r state_most`. In 2002, the median of the "Excellent" response value was `r median(filter(brfss_smart2010, year == 2002)$excellent, na.rm = TRUE)`.


Make a histogram of "Excellent" response values in the year 2002: 

```{r, excellent_histogram}
library(ggplot2)
ggplot(data = filter(brfss_smart2010, year == 2002), aes(x = excellent)) + geom_histogram() + 
  labs(
    title = "'Excellent' Response Values in 2002",
    x = "Proportion of 'Excellent' Responses",
    y = "Count"
  )
```

Make a scatterplot showing the proportion of "Excellent" response values in New York County and Queens County in each year from 2002 to 2010:

```{r, excellent_scatterplot}
ggplot(data = filter(brfss_smart2010, locationdesc == "NY - New York County" | locationdesc == "NY - Queens County"), aes(x = year, y = excellent, color = locationdesc)) + geom_point() +
  labs(
    title = "'Excellent' Response Values",
    x = "Year",
    y = "Proportion of 'Excellent' Responses",
    color = "Location"
  ) +
  theme(legend.position = "bottom")
```

